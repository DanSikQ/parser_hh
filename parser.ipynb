{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-15T08:29:52.747621Z",
     "start_time": "2025-07-15T08:29:52.744119Z"
    }
   },
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "import psycopg2"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:31:11.525958Z",
     "start_time": "2025-07-15T08:30:48.230579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "info_vac_v1 = pd.DataFrame()\n",
    "\n",
    "for i in range(0,19):\n",
    "    \n",
    "    params = {\n",
    "        'text': '!(аналитик данных OR data analyst OR бизнес-аналитик OR BI-аналитик or data engineer)', # Текст фильтра\n",
    "        'area': 1, # Поиск ощуществляется по вакансиям города Москва\n",
    "        'page': i, # Индекс страницы поиска на HH\n",
    "        'per_page': 100 # Кол-во вакансий на 1 странице\n",
    "        }\n",
    "    \n",
    "    req = requests.get('https://api.hh.ru/vacancies', params) # Посылаем запрос к API\n",
    "    data = req.content.decode() # Декодируем его ответ, чтобы Кириллица отображалась корректно\n",
    "    time.sleep(0.5)\n",
    "    req.close()\n",
    "    json_data = json.loads(data)\n",
    "    new_data = pd.DataFrame(json_data['items']).reset_index(drop=True)\n",
    "    info_vac_v1 = pd.concat([info_vac_v1, new_data], ignore_index=True)"
   ],
   "id": "3bcdbf13cdf9a8d9",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:31:47.451605Z",
     "start_time": "2025-07-15T08:31:47.228298Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "salary = pd.json_normalize(info_vac_v1['salary'])\n",
    "address = pd.json_normalize(info_vac_v1['address'])\n",
    "\n",
    "address = address.drop(columns=['id'])\n",
    "\n",
    "employer = pd.json_normalize(info_vac_v1['employer'])\n",
    "employer = employer.drop(columns=['logo_urls.90', 'logo_urls.240', 'url', 'alternate_url', 'vacancies_url', 'logo_urls.original', 'logo_urls' ])\n",
    "employer = employer.rename(columns={'id': 'id_employer', \"name\": \"name_employer\"})\n",
    "\n",
    "snippet = pd.json_normalize(info_vac_v1['snippet'])\n",
    "\n",
    "schedule = pd.json_normalize(info_vac_v1['schedule'])\n",
    "schedule.drop(columns=['id'], inplace=True)\n",
    "schedule.rename(columns={'name': 'schedules'}, inplace=True)\n",
    "\n",
    "def sep_list_columns(list):\n",
    "    length = len(list)\n",
    "    if length >= 1:\n",
    "        return list[0]\n",
    "\n",
    "work_format = pd.json_normalize(info_vac_v1['work_format'].apply(sep_list_columns))\n",
    "work_format.rename(columns={'name': 'format_works'}, inplace=True)\n",
    "\n",
    "working_hours = pd.json_normalize(info_vac_v1['working_hours'].apply(sep_list_columns))\n",
    "working_hours.rename(columns={'name': 'hours_working'}, inplace=True)\n",
    "\n",
    "work_schedule_by_days = pd.json_normalize(info_vac_v1['work_schedule_by_days'].apply(sep_list_columns))\n",
    "work_schedule_by_days.rename(columns={'name': 'schedule_work_by_days'}, inplace=True)\n",
    "\n",
    "professional_roles = pd.json_normalize(info_vac_v1['professional_roles'].apply(sep_list_columns))\n",
    "professional_roles.rename(columns={'name': 'roles_professional'}, inplace=True)\n",
    "\n",
    "experience = pd.json_normalize(info_vac_v1['experience'])\n",
    "experience = experience.drop(columns=['id'])\n",
    "experience = experience.rename(columns={'name': 'experience_'})\n",
    "\n",
    "employment = pd.json_normalize(info_vac_v1['employment'])\n",
    "employment = employment.drop(columns=['id'])\n",
    "employment = employment.rename(columns={'name': 'employment_'})\n",
    "\n",
    "info_vac_v1 = pd.concat([info_vac_v1, salary, address, employer, snippet, schedule, work_format['format_works'], working_hours['hours_working'], work_schedule_by_days['schedule_work_by_days'], professional_roles['roles_professional'], experience['experience_'], employment['employment_']], axis = 1)\n",
    "info_vac_v1 = info_vac_v1.drop(\n",
    "    columns=['area', 'salary', 'employment_form', 'salary_range', 'type', 'address', 'employer', 'contacts', 'snippet',\n",
    "             'schedule', 'work_format', 'employment_form', 'working_hours', 'work_schedule_by_days',\n",
    "             'professional_roles', 'experience', 'employment', 'metro_stations', 'branding', 'department', 'description', 'insider_interview', 'response_url', 'sort_point_distance','adv_response_url','adv_context','metro','relations', 'working_days',\n",
    "             'working_time_intervals', 'working_time_modes', 'fly_in_fly_out_duration', 'night_shifts', 'is_adv_vacancy', 'archived', 'show_logo_in_search', 'show_contacts', 'video_vacancy', 'brand_snippet', 'employer_rating', 'created_at', 'url', 'accept_temporary', 'accept_incomplete_resumes', 'internship', 'metro.station_id', 'metro.line_id', 'metro.lat', 'metro.lng'\n",
    "             ])\n",
    "\n",
    "exchange_rates = {\n",
    "    'USD': 80.0,  # 1 USD = 80 RUB\n",
    "    'EUR': 90.0,  # 1 EUR = 90 RUB\n",
    "    'RUR': 1.0     # 1 RUB = 1 RUB\n",
    "}\n",
    "\n",
    "def check_salary(row):\n",
    "    \n",
    "    if pd.isna(row['to']) and pd.isna(row['from']):\n",
    "        return np.nan\n",
    "    elif pd.isna(row['to']):\n",
    "        total_salary = row['from']\n",
    "    elif pd.isna(row['from']):\n",
    "        total_salary = row['to']\n",
    "    else:\n",
    "        total_salary = (row['from'] + row['to']) / 2\n",
    "    \n",
    "    currency = row['currency']\n",
    "    if pd.notna(currency):\n",
    "        total_salary *= exchange_rates.get(currency, 1.0) # Конвертация в рубли\n",
    "    if pd.notna(row['gross']) and row['gross'] == True:\n",
    "        total_salary *= 0.87 # Вычет налогов\n",
    "    return total_salary\n",
    "\n",
    "info_vac_v1['total_salary'] = info_vac_v1.apply(check_salary, axis = 1)"
   ],
   "id": "e0188c6aadca731",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:51:02.718528Z",
     "start_time": "2025-07-15T08:32:39.470819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "description_info = []\n",
    "for id in info_vac_v1['id']:\n",
    "    try:\n",
    "        # Делаем запрос к API\n",
    "        req_vac = requests.get(f'https://api.hh.ru/vacancies/{id}') \n",
    "        req_vac.raise_for_status() \n",
    "        data = req_vac.content.decode() \n",
    "        req_vac.close()\n",
    "        \n",
    "        time.sleep(0.4)  # Задержка между запросами\n",
    "        \n",
    "        data_vac = json.loads(data)\n",
    "        \n",
    "        # Обработка skills с проверкой наличия ключа\n",
    "        skills = []\n",
    "        if 'key_skills' in data_vac and isinstance(data_vac['key_skills'], list):\n",
    "            skills = [i['name'] for i in data_vac['key_skills']]\n",
    "        \n",
    "        description_info.append({\n",
    "            'vacancy_id': id,\n",
    "            'description': data_vac.get('description', ''), \n",
    "            'key_skills_under_desc': skills,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Неожиданная ошибка для вакансии {id}: {e}\")\n",
    "        continue\n",
    "        "
   ],
   "id": "a4cbf1fff30f5f60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Неожиданная ошибка для вакансии 122763718: 404 Client Error: Not Found for url: https://api.hh.ru/vacancies/122763718\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "60bcb5920bbe9d89"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T08:53:16.473012Z",
     "start_time": "2025-07-15T08:53:16.341371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_description_info = pd.DataFrame(description_info)\n",
    "info_vac_merge = info_vac_v1.merge(df_description_info, left_on='id', right_on='vacancy_id', how='left').drop(columns = ['vacancy_id'])\n",
    "\n",
    "info_vac_merge.rename(columns={'description_y': 'description',\n",
    "                         'key_skills_under_desc_y': 'key_skills_under_desc'}, inplace=True)\n",
    "info_vac_merge.to_csv('info_vac.csv')"
   ],
   "id": "27ccf592dd3d705",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T10:59:47.827774Z",
     "start_time": "2025-07-15T10:59:33.437370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skills_keywords = [\n",
    "    # Языки программирования\n",
    "    'SQL', 'Python', 'R', 'Scala', 'Java', 'C#', 'Julia', '1C',\n",
    "    \n",
    "    # BI и визуализация\n",
    "    'Power BI', 'Tableau', 'Qlik', 'Looker', 'Metabase', 'Redash', 'Superset',\n",
    "    'Excel', 'Google Sheets', 'Data Studio', 'Plotly', 'Matplotlib', 'Seaborn',\n",
    "    \n",
    "    # Базы данных\n",
    "    'PostgreSQL', 'MySQL', 'MS SQL', 'Oracle', 'ClickHouse', 'Greenplum',\n",
    "    'MongoDB', 'Redis', 'Cassandra', 'Snowflake', 'BigQuery', 'Redshift',\n",
    "    \n",
    "    # Big Data\n",
    "    'Hadoop', 'Spark', 'Hive', 'Kafka', 'Airflow', 'Flink', 'Databricks',\n",
    "    \n",
    "    # Облачные платформы\n",
    "    'AWS', 'Azure', 'GCP', 'Yandex Cloud', 'IBM Cloud',\n",
    "    \n",
    "    # ETL и обработка данных\n",
    "    'DWH', 'ETL', 'ELT', 'Data Vault', 'Data Lake', 'Data Mesh',\n",
    "    'Informatica', 'Talend', 'SSIS', 'Alteryx', 'dbt', 'Apache NiFi',\n",
    "    \n",
    "    # Аналитика\n",
    "    'Machine Learning', 'ML', 'AI', 'Deep Learning', 'NLP', 'Computer Vision',\n",
    "    'Statistics', 'A/B тестирование', 'Predictive Modeling', 'Time Series',\n",
    "    'EDA', 'Feature Engineering', 'MLflow', 'Kubeflow',\n",
    "    \n",
    "    # Управление\n",
    "    'Scrum', 'Agile', 'Kanban', 'Jira', 'Confluence', 'Git', 'CI/CD',\n",
    "    \n",
    "    # Дополнительные технологии\n",
    "    'Docker', 'Kubernetes', 'Linux', 'Bash', 'Pandas', 'NumPy', 'SciPy',\n",
    "    'Scikit-learn', 'TensorFlow', 'PyTorch', 'Keras', 'XGBoost', 'CatBoost',\n",
    "    'LightGBM', 'OpenCV', 'NLTK', 'spaCy', 'Hugging Face', 'REST', 'API', 'request', 'WebSocket'\n",
    "    \n",
    "    # Математика\n",
    "    'Математика', 'Статистика', 'Математический анализ', 'Линейная алгебра', \n",
    "    'Теория Вероятностей', 'Дискретная математика']\n",
    "\n",
    "\n",
    "def extract_skills(desc):\n",
    "    found_skills = []\n",
    "    desc = str(desc).lower()\n",
    "    for skill in skills_keywords:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', desc):\n",
    "            found_skills.append(skill)\n",
    "    return found_skills\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "def check_intern_nlp(desc):\n",
    "    \n",
    "    doc = nlp(desc.lower()) \n",
    "\n",
    "    internship_lemmas = {\n",
    "        \"интерн\", \"стажёр\", \n",
    "        \"intern\", \"trainee\" \n",
    "    }\n",
    "    for token in doc:\n",
    "        # Проверяем лемму (начальную форму) слова\n",
    "        if token.lemma_ in internship_lemmas:\n",
    "            return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "info_vac_merge = pd.read_csv('info_vac.csv', index_col=0)\n",
    "\n",
    "info_vac_merge.columns = map(lambda x: x.replace('.', '_'), info_vac_merge.columns.to_list())\n",
    "\n",
    "info_vac_merge['skills_in_desc'] = info_vac_merge['description'].apply(extract_skills)\n",
    "info_vac_merge = info_vac_merge[info_vac_merge['id'].notna()]\n",
    "info_vac_merge['is_intern'] = info_vac_merge['name'].apply(check_intern_nlp)\n",
    "info_vac_merge = info_vac_merge[info_vac_merge['id_employer'].notna()]\n",
    "info_vac_merge['published_at'] = pd.to_datetime(info_vac_merge['published_at'], utc = True)\n",
    "info_vac_merge.rename(columns={'from': 'from_salary',\n",
    "                               'to': 'to_salary'}, inplace=True)\n",
    "\n",
    "skills_desc = info_vac_merge['skills_in_desc'].explode('skills_in_desc')\n",
    "skills_counts = skills_desc.value_counts()\n",
    "vacancy_skills = info_vac_merge[['id', 'skills_in_desc']].explode('skills_in_desc')\n",
    "\n",
    "employer = info_vac_merge[['id_employer', 'name_employer', 'accredited_it_employer', 'trusted', 'employer_rating_total_rating', 'employer_rating_reviews_count']].drop_duplicates(subset = ['id_employer'], keep = 'first')\n",
    "employer = employer[employer['id_employer'].notna()]\n",
    "employer.rename(columns = {'employer_rating_total_rating': 'total_rating', 'employer_rating_reviews_count': 'reviews_count'}, inplace=True)\n",
    "\n",
    "info_vac_merge.drop(columns=['name_employer', 'accredited_it_employer', 'trusted', 'employer_rating_total_rating', 'employer_rating_reviews_count'], inplace=True)"
   ],
   "id": "eb22571b31dfef6b",
   "outputs": [],
   "execution_count": 91
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "19fa43e6eb6eaf57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-15T11:00:11.942171Z",
     "start_time": "2025-07-15T11:00:11.187598Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5433',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': '123'\n",
    "}\n",
    "\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS employers (\n",
    "              id_employer INTEGER PRIMARY KEY,\n",
    "              name_employer VARCHAR(200),\n",
    "              accredited_it_employer TEXT,\n",
    "              trusted BOOLEAN,\n",
    "              total_rating NUMERIC(10, 2),\n",
    "              reviews_count NUMERIC(10,2));\n",
    "          \"\"\")\n",
    "        \n",
    "        columns = ', '.join(employer.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(employer.columns))\n",
    "        for _, row in employer.iterrows():\n",
    "            cursor.execute(f\"INSERT INTO employers ({columns}) \"\n",
    "                            f\"VALUES ({placeholders})\"\n",
    "                            f\"ON CONFLICT (id_employer) DO NOTHING\", tuple(row))\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS vacancy (\n",
    "              id INTEGER PRIMARY KEY,\n",
    "              premium BOOLEAN,\n",
    "              name TEXT,\n",
    "              has_test BOOLEAN,\n",
    "              response_letter_required BOOLEAN,\n",
    "              published_at TIMESTAMP WITH TIME ZONE,\n",
    "              apply_alternate_url TEXT,\n",
    "              alternate_url TEXT,\n",
    "              from_salary NUMERIC(10,2),\n",
    "              to_salary NUMERIC(10,2),\n",
    "              currency VARCHAR(20),\n",
    "              gross TEXT,\n",
    "              city TEXT,\n",
    "              street TEXT,\n",
    "              building TEXT,\n",
    "              lat NUMERIC(10,6),\n",
    "              lng NUMERIC(10,6),\n",
    "              raw TEXT,\n",
    "              metro_station_name TEXT,\n",
    "              metro_line_name TEXT,\n",
    "              id_employer INTEGER REFERENCES employers(id_employer),\n",
    "              requirement TEXT,\n",
    "              responsibility TEXT,\n",
    "              schedules TEXT,\n",
    "              format_works TEXT, \n",
    "              hours_working TEXT,\n",
    "              schedule_work_by_days TEXT,\n",
    "              roles_professional TEXT,\n",
    "              experience_ TEXT,\n",
    "              employment_ TEXT, \n",
    "              total_salary NUMERIC(10,2),\n",
    "              description TEXT, \n",
    "              key_skills_under_desc TEXT,\n",
    "              skills_in_desc TEXT,\n",
    "              is_intern BOOLEAN   \n",
    "              );\n",
    "          \"\"\")\n",
    "        \n",
    "        columns = ', '.join(info_vac_merge.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(info_vac_merge.columns))\n",
    "        for _, row in info_vac_merge.iterrows():\n",
    "            try:\n",
    "                cursor.execute(f\"INSERT INTO vacancy ({columns})\"\n",
    "                            f\"VALUES ({placeholders})\"\n",
    "                            f\"ON CONFLICT (id) DO NOTHING\", tuple(row))\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка в строке с id={row['id']}: {e}\")\n",
    "                print(f\"Данные строки: {row.to_dict()}\")\n",
    "                raise\n",
    "        conn.commit()"
   ],
   "id": "40a404007711f7ca",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d662ae14a07e8c5e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
