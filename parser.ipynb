{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T10:52:25.968881Z",
     "start_time": "2025-07-30T10:52:25.965878Z"
    }
   },
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "import psycopg2\n",
    "# apache-airflow[all]"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:52:26.711187Z",
     "start_time": "2025-07-30T10:52:26.000483Z"
    }
   },
   "cell_type": "code",
   "source": [
    "info_vac_v1 = pd.DataFrame()\n",
    "\n",
    "for i in range(0,1):\n",
    "    \n",
    "    params = {\n",
    "        'text': '!(аналитик данных OR data analyst OR бизнес-аналитик OR BI-аналитик or data engineer)', # Текст фильтра\n",
    "        'area': 1, # Поиск ощуществляется по вакансиям города Москва\n",
    "        'page': i, # Индекс страницы поиска на HH\n",
    "        'per_page': 10 # Кол-во вакансий на 1 странице\n",
    "        }\n",
    "    \n",
    "    req = requests.get('https://api.hh.ru/vacancies', params) # Посылаем запрос к API\n",
    "    data = req.content.decode() # Декодируем его ответ, чтобы Кириллица отображалась корректно\n",
    "    time.sleep(0.5)\n",
    "    req.close()\n",
    "    json_data = json.loads(data)\n",
    "    new_data = pd.DataFrame(json_data['items']).reset_index(drop=True)\n",
    "    info_vac_v1 = pd.concat([info_vac_v1, new_data], ignore_index=True)"
   ],
   "id": "3bcdbf13cdf9a8d9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:52:26.766512Z",
     "start_time": "2025-07-30T10:52:26.750404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "salary = pd.json_normalize(info_vac_v1['salary'])\n",
    "address = pd.json_normalize(info_vac_v1['address'])\n",
    "\n",
    "address = address.drop(columns=['id'])\n",
    "\n",
    "employer = pd.json_normalize(info_vac_v1['employer'])\n",
    "\n",
    "employer_to_drop = ['logo_urls.90', 'logo_urls.240', 'url', 'alternate_url', 'vacancies_url', 'logo_urls.original', 'logo_urls']\n",
    "employer_exist_to_drop = [col for col in employer_to_drop if col in employer.columns]\n",
    "employer = employer.drop(columns=employer_exist_to_drop)\n",
    "employer = employer.rename(columns={'id': 'id_employer', \"name\": \"name_employer\"})\n",
    "\n",
    "snippet = pd.json_normalize(info_vac_v1['snippet'])\n",
    "\n",
    "schedule = pd.json_normalize(info_vac_v1['schedule'])\n",
    "schedule.drop(columns=['id'], inplace=True)\n",
    "schedule.rename(columns={'name': 'schedules'}, inplace=True)\n",
    "\n",
    "def sep_list_columns(list):\n",
    "    length = len(list)\n",
    "    if length >= 1:\n",
    "        return list[0]\n",
    "\n",
    "work_format = pd.json_normalize(info_vac_v1['work_format'].apply(sep_list_columns))\n",
    "work_format.rename(columns={'name': 'format_works'}, inplace=True)\n",
    "\n",
    "working_hours = pd.json_normalize(info_vac_v1['working_hours'].apply(sep_list_columns))\n",
    "working_hours.rename(columns={'name': 'hours_working'}, inplace=True)\n",
    "\n",
    "work_schedule_by_days = pd.json_normalize(info_vac_v1['work_schedule_by_days'].apply(sep_list_columns))\n",
    "work_schedule_by_days.rename(columns={'name': 'schedule_work_by_days'}, inplace=True)\n",
    "\n",
    "professional_roles = pd.json_normalize(info_vac_v1['professional_roles'].apply(sep_list_columns))\n",
    "professional_roles.rename(columns={'name': 'roles_professional'}, inplace=True)\n",
    "\n",
    "experience = pd.json_normalize(info_vac_v1['experience'])\n",
    "experience = experience.drop(columns=['id'])\n",
    "experience = experience.rename(columns={'name': 'experience_'})\n",
    "\n",
    "employment = pd.json_normalize(info_vac_v1['employment'])\n",
    "employment = employment.drop(columns=['id'])\n",
    "employment = employment.rename(columns={'name': 'employment_'})\n",
    "\n",
    "info_vac_v1 = pd.concat([info_vac_v1, salary, address, employer, snippet, schedule, work_format['format_works'], working_hours['hours_working'], work_schedule_by_days['schedule_work_by_days'], professional_roles['roles_professional'], experience['experience_'], employment['employment_']], axis = 1)\n",
    "\n",
    "columns_to_drop = [\n",
    "    'area', 'salary', 'employment_form', 'salary_range', 'type', 'address', \n",
    "    'employer', 'contacts', 'snippet', 'schedule', 'work_format', \n",
    "    'employment_form', 'working_hours', 'work_schedule_by_days',\n",
    "    'professional_roles', 'experience', 'employment', 'metro_stations', \n",
    "    'branding', 'department', 'description', 'insider_interview', \n",
    "    'response_url', 'sort_point_distance', 'adv_response_url', 'adv_context',\n",
    "    'metro', 'relations', 'working_days', 'working_time_intervals', \n",
    "    'working_time_modes', 'fly_in_fly_out_duration', 'night_shifts', \n",
    "    'is_adv_vacancy', 'archived', 'show_logo_in_search', 'show_contacts', \n",
    "    'brand_snippet', 'created_at', 'url', 'accept_temporary', \n",
    "    'accept_incomplete_resumes', 'internship', 'metro.station_id', \n",
    "    'metro.line_id', 'metro.lat', 'metro.lng'\n",
    "]\n",
    "\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in info_vac_v1.columns]\n",
    "\n",
    "info_vac_v1 = info_vac_v1.drop(columns=existing_columns_to_drop)\n",
    "\n",
    "exchange_rates = {\n",
    "    'USD': 80.0,  # 1 USD = 80 RUB\n",
    "    'EUR': 90.0,  # 1 EUR = 90 RUB\n",
    "    'RUR': 1.0     # 1 RUB = 1 RUB\n",
    "}\n",
    "\n",
    "def check_salary(row):\n",
    "\n",
    "    if pd.isna(row['to']) and pd.isna(row['from']):\n",
    "        return np.nan\n",
    "    elif pd.isna(row['to']):\n",
    "        total_salary = row['from']\n",
    "    elif pd.isna(row['from']):\n",
    "        total_salary = row['to']\n",
    "    else:\n",
    "        total_salary = (row['from'] + row['to']) / 2\n",
    "\n",
    "    currency = row['currency']\n",
    "    if pd.notna(currency):\n",
    "        total_salary *= exchange_rates.get(currency, 1.0) # Конвертация в рубли\n",
    "    if pd.notna(row['gross']) and row['gross'] == True:\n",
    "        total_salary *= 0.87 # Вычет налогов\n",
    "    return total_salary\n",
    "\n",
    "info_vac_v1['total_salary'] = info_vac_v1.apply(check_salary, axis = 1)"
   ],
   "id": "e0188c6aadca731",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:52:32.410977Z",
     "start_time": "2025-07-30T10:52:26.801223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "description_info = []\n",
    "for id in info_vac_v1['id']:\n",
    "    try:\n",
    "        # Делаем запрос к API\n",
    "        req_vac = requests.get(f'https://api.hh.ru/vacancies/{id}') \n",
    "        req_vac.raise_for_status() \n",
    "        data = req_vac.content.decode() \n",
    "        req_vac.close()\n",
    "        \n",
    "        time.sleep(0.4)  # Задержка между запросами\n",
    "        \n",
    "        data_vac = json.loads(data)\n",
    "        \n",
    "        # Обработка skills с проверкой наличия ключа\n",
    "        skills = []\n",
    "        if 'key_skills' in data_vac and isinstance(data_vac['key_skills'], list):\n",
    "            skills = [i['name'] for i in data_vac['key_skills']]\n",
    "        \n",
    "        description_info.append({\n",
    "            'vacancy_id': id,\n",
    "            'description': data_vac.get('description', ''), \n",
    "            'key_skills_under_desc': skills,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Неожиданная ошибка для вакансии {id}: {e}\")\n",
    "        continue\n",
    "        "
   ],
   "id": "a4cbf1fff30f5f60",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:52:32.452816Z",
     "start_time": "2025-07-30T10:52:32.444141Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_description_info = pd.DataFrame(description_info)\n",
    "info_vac_merge = info_vac_v1.merge(df_description_info, left_on='id', right_on='vacancy_id', how='left').drop(columns = ['vacancy_id'])\n",
    "\n",
    "info_vac_merge.rename(columns={'description_y': 'description',\n",
    "                         'key_skills_under_desc_y': 'key_skills_under_desc'}, inplace=True)\n",
    "info_vac_merge.to_csv('info_vac.csv')"
   ],
   "id": "27ccf592dd3d705",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:52:33.481612Z",
     "start_time": "2025-07-30T10:52:32.484161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skills_keywords = [\n",
    "    # Языки программирования\n",
    "    'SQL', 'Python', 'R', 'Scala', 'Java', 'C#', 'Julia', '1C',\n",
    "    \n",
    "    # BI и визуализация\n",
    "    'Power BI', 'Tableau', 'Qlik', 'Looker', 'Metabase', 'Redash', 'Superset',\n",
    "    'Excel', 'Google Sheets', 'Data Studio', 'Plotly', 'Matplotlib', 'Seaborn',\n",
    "    \n",
    "    # Базы данных\n",
    "    'PostgreSQL', 'MySQL', 'MS SQL', 'Oracle', 'ClickHouse', 'Greenplum',\n",
    "    'MongoDB', 'Redis', 'Cassandra', 'Snowflake', 'BigQuery', 'Redshift',\n",
    "    \n",
    "    # Big Data\n",
    "    'Hadoop', 'Spark', 'Hive', 'Kafka', 'Airflow', 'Flink', 'Databricks',\n",
    "    \n",
    "    # Облачные платформы\n",
    "    'AWS', 'Azure', 'GCP', 'Yandex Cloud', 'IBM Cloud',\n",
    "    \n",
    "    # ETL и обработка данных\n",
    "    'DWH', 'ETL', 'ELT', 'Data Vault', 'Data Lake', 'Data Mesh',\n",
    "    'Informatica', 'Talend', 'SSIS', 'Alteryx', 'dbt', 'Apache NiFi',\n",
    "    \n",
    "    # Аналитика\n",
    "    'Machine Learning', 'ML', 'AI', 'Deep Learning', 'NLP', 'Computer Vision',\n",
    "    'Statistics', 'A/B тестирование', 'Predictive Modeling', 'Time Series',\n",
    "    'EDA', 'Feature Engineering', 'MLflow', 'Kubeflow',\n",
    "    \n",
    "    # Управление\n",
    "    'Scrum', 'Agile', 'Kanban', 'Jira', 'Confluence', 'Git', 'CI/CD',\n",
    "    \n",
    "    # Дополнительные технологии\n",
    "    'Docker', 'Kubernetes', 'Linux', 'Bash', 'Pandas', 'NumPy', 'SciPy',\n",
    "    'Scikit-learn', 'TensorFlow', 'PyTorch', 'Keras', 'XGBoost', 'CatBoost',\n",
    "    'LightGBM', 'OpenCV', 'NLTK', 'spaCy', 'Hugging Face', 'REST', 'API', 'request', 'WebSocket',\n",
    "    \n",
    "    # Математика\n",
    "    'Математика', 'Статистика', 'Математический анализ', 'Линейная алгебра', \n",
    "    'Теория Вероятностей', 'Дискретная математика']\n",
    "\n",
    "\n",
    "def extract_skills(desc):\n",
    "    found_skills = []\n",
    "    desc = str(desc).lower()\n",
    "    for skill in skills_keywords:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', desc):\n",
    "            found_skills.append(skill)\n",
    "    return found_skills\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "def check_intern_nlp(desc):\n",
    "    \n",
    "    doc = nlp(desc.lower()) \n",
    "\n",
    "    internship_lemmas = {\n",
    "        \"интерн\", \"стажёр\", \n",
    "        \"intern\", \"trainee\" \n",
    "    }\n",
    "    for token in doc:\n",
    "        # Проверяем лемму (начальную форму) слова\n",
    "        if token.lemma_ in internship_lemmas:\n",
    "            return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "info_vac_merge = pd.read_csv('info_vac.csv', index_col=0)\n",
    "\n",
    "info_vac_merge.columns = map(lambda x: x.replace('.', '_'), info_vac_merge.columns.to_list())\n",
    "\n",
    "info_vac_merge['skills_in_desc'] = info_vac_merge['description'].apply(extract_skills)\n",
    "\n",
    "info_vac_merge = info_vac_merge[info_vac_merge['id'].notna()]\n",
    "info_vac_merge['is_intern'] = info_vac_merge['name'].apply(check_intern_nlp)\n",
    "info_vac_merge = info_vac_merge[info_vac_merge['id_employer'].notna()]\n",
    "info_vac_merge['published_at'] = pd.to_datetime(info_vac_merge['published_at'], utc = True)\n",
    "info_vac_merge.rename(columns={'from': 'from_salary',\n",
    "                               'to': 'to_salary'}, inplace=True)\n",
    "\n",
    "skills_desc = info_vac_merge['skills_in_desc'].explode('skills_in_desc')\n",
    "skills_counts = skills_desc.value_counts()\n",
    "vacancy_skills = info_vac_merge[['id', 'skills_in_desc']].explode('skills_in_desc')\n",
    "\n",
    "employer = info_vac_merge[['id_employer', 'name_employer', 'accredited_it_employer', 'trusted']].drop_duplicates(subset = ['id_employer'], keep = 'first')\n",
    "employer = employer[employer['id_employer'].notna()]\n",
    "\n",
    "info_vac_merge.drop(columns=['name_employer', 'accredited_it_employer', 'trusted'], inplace=True)"
   ],
   "id": "eb22571b31dfef6b",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "19fa43e6eb6eaf57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:52:33.569986Z",
     "start_time": "2025-07-30T10:52:33.515086Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5433',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': '123'\n",
    "}\n",
    "\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS employers (\n",
    "              id_employer INTEGER PRIMARY KEY,\n",
    "              name_employer VARCHAR(200),\n",
    "              accredited_it_employer TEXT,\n",
    "              trusted BOOLEAN);\n",
    "          \"\"\")\n",
    "        \n",
    "        columns = ', '.join(employer.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(employer.columns))\n",
    "        for _, row in employer.iterrows():\n",
    "            cursor.execute(f\"INSERT INTO employers ({columns}) \"\n",
    "                            f\"VALUES ({placeholders})\"\n",
    "                            f\"ON CONFLICT (id_employer) DO NOTHING\", tuple(row))\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS vacancy (\n",
    "              id INTEGER PRIMARY KEY,\n",
    "              premium BOOLEAN,\n",
    "              name TEXT,\n",
    "              has_test BOOLEAN,\n",
    "              response_letter_required BOOLEAN,\n",
    "              published_at TIMESTAMP WITH TIME ZONE,\n",
    "              apply_alternate_url TEXT,\n",
    "              alternate_url TEXT,\n",
    "              from_salary NUMERIC(10,2),\n",
    "              to_salary NUMERIC(10,2),\n",
    "              currency VARCHAR(20),\n",
    "              gross TEXT,\n",
    "              city TEXT,\n",
    "              street TEXT,\n",
    "              building TEXT,\n",
    "              lat NUMERIC(10,6),\n",
    "              lng NUMERIC(10,6),\n",
    "              raw TEXT,\n",
    "              metro_station_name TEXT,\n",
    "              metro_line_name TEXT,\n",
    "              id_employer INTEGER REFERENCES employers(id_employer),\n",
    "              requirement TEXT,\n",
    "              responsibility TEXT,\n",
    "              schedules TEXT,\n",
    "              format_works TEXT, \n",
    "              hours_working TEXT,\n",
    "              schedule_work_by_days TEXT,\n",
    "              roles_professional TEXT,\n",
    "              experience_ TEXT,\n",
    "              employment_ TEXT, \n",
    "              total_salary NUMERIC(10,2),\n",
    "              description TEXT, \n",
    "              key_skills_under_desc TEXT,\n",
    "              skills_in_desc TEXT,\n",
    "              is_intern BOOLEAN   \n",
    "              );\n",
    "          \"\"\")\n",
    "        \n",
    "        columns = ', '.join(info_vac_merge.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(info_vac_merge.columns))\n",
    "        for _, row in info_vac_merge.iterrows():\n",
    "            cursor.execute(f\"INSERT INTO vacancy ({columns})\"\n",
    "                            f\"VALUES ({placeholders})\"\n",
    "                            f\"ON CONFLICT (id) DO NOTHING\", tuple(row))\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS skills (\n",
    "              id INTEGER REFERENCES vacancy(id),\n",
    "              skills_in_desc TEXT\n",
    "              );\n",
    "          \"\"\")\n",
    "        \n",
    "        columns = ', '.join(vacancy_skills.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(vacancy_skills.columns))\n",
    "        for _, row in vacancy_skills.iterrows():\n",
    "            cursor.execute(f\"INSERT INTO skills ({columns})\"\n",
    "                            f\"VALUES ({placeholders})\", tuple(row))\n",
    "        conn.commit()\n",
    "        \n",
    "        "
   ],
   "id": "40a404007711f7ca",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:52:33.609592Z",
     "start_time": "2025-07-30T10:52:33.603276Z"
    }
   },
   "cell_type": "code",
   "source": "vacancy_skills",
   "id": "53f500cc89447a00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "          id skills_in_desc\n",
       "0  123362863            SQL\n",
       "0  123362863         Python\n",
       "0  123362863        Tableau\n",
       "0  123362863       Metabase\n",
       "0  123362863         Redash\n",
       "1  123391639            SQL\n",
       "1  123391639          Agile\n",
       "1  123391639           Jira\n",
       "1  123391639            API\n",
       "2  123297622            SQL\n",
       "2  123297622            ETL\n",
       "3  123362968            NaN\n",
       "4  123378282            SQL\n",
       "4  123378282         Python\n",
       "4  123378282       Superset\n",
       "4  123378282         Oracle\n",
       "4  123378282     Kubernetes\n",
       "4  123378282         Pandas\n",
       "5  123414998            SQL\n",
       "5  123414998         Python\n",
       "5  123414998     PostgreSQL\n",
       "5  123414998          Kafka\n",
       "5  123414998          Scrum\n",
       "5  123414998          Agile\n",
       "5  123414998          CI/CD\n",
       "5  123414998         Docker\n",
       "5  123414998           REST\n",
       "5  123414998            API\n",
       "6  123410456          Excel\n",
       "7  123415026            SQL\n",
       "7  123415026          Excel\n",
       "8  123259817         Python\n",
       "8  123259817  Google Sheets\n",
       "8  123259817          MySQL\n",
       "8  123259817         Pandas\n",
       "8  123259817            API\n",
       "9  123351983            NaN"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>skills_in_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123362863</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123362863</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123362863</td>\n",
       "      <td>Tableau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123362863</td>\n",
       "      <td>Metabase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123362863</td>\n",
       "      <td>Redash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123391639</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123391639</td>\n",
       "      <td>Agile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123391639</td>\n",
       "      <td>Jira</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>123391639</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123297622</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123297622</td>\n",
       "      <td>ETL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>123362968</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123378282</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123378282</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123378282</td>\n",
       "      <td>Superset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123378282</td>\n",
       "      <td>Oracle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123378282</td>\n",
       "      <td>Kubernetes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>123378282</td>\n",
       "      <td>Pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>PostgreSQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>Kafka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>Scrum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>Agile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>CI/CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>Docker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>REST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>123414998</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>123410456</td>\n",
       "      <td>Excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>123415026</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>123415026</td>\n",
       "      <td>Excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>123259817</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>123259817</td>\n",
       "      <td>Google Sheets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>123259817</td>\n",
       "      <td>MySQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>123259817</td>\n",
       "      <td>Pandas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>123259817</td>\n",
       "      <td>API</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123351983</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d662ae14a07e8c5e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
