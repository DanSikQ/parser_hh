{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-30T09:53:14.845060Z",
     "start_time": "2025-07-30T09:53:11.238205Z"
    }
   },
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "import spacy\n",
    "import psycopg2"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T09:56:17.255283Z",
     "start_time": "2025-07-30T09:56:13.643615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "info_vac_v1 = pd.DataFrame()\n",
    "\n",
    "for i in range(0,3):\n",
    "    \n",
    "    params = {\n",
    "        'text': '!(аналитик данных OR data analyst OR бизнес-аналитик OR BI-аналитик or data engineer)', # Текст фильтра\n",
    "        'area': 1, # Поиск ощуществляется по вакансиям города Москва\n",
    "        'page': i, # Индекс страницы поиска на HH\n",
    "        'per_page': 100 # Кол-во вакансий на 1 странице\n",
    "        }\n",
    "    \n",
    "    req = requests.get('https://api.hh.ru/vacancies', params) # Посылаем запрос к API\n",
    "    data = req.content.decode() # Декодируем его ответ, чтобы Кириллица отображалась корректно\n",
    "    time.sleep(0.5)\n",
    "    req.close()\n",
    "    json_data = json.loads(data)\n",
    "    new_data = pd.DataFrame(json_data['items']).reset_index(drop=True)\n",
    "    info_vac_v1 = pd.concat([info_vac_v1, new_data], ignore_index=True)"
   ],
   "id": "3bcdbf13cdf9a8d9",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T09:56:18.978511Z",
     "start_time": "2025-07-30T09:56:18.950512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "salary = pd.json_normalize(info_vac_v1['salary'])\n",
    "address = pd.json_normalize(info_vac_v1['address'])\n",
    "\n",
    "address = address.drop(columns=['id'])\n",
    "\n",
    "employer = pd.json_normalize(info_vac_v1['employer'])\n",
    "employer = employer.drop(columns=['logo_urls.90', 'logo_urls.240', 'url', 'alternate_url', 'vacancies_url', 'logo_urls.original', 'logo_urls' ])\n",
    "employer = employer.rename(columns={'id': 'id_employer', \"name\": \"name_employer\"})\n",
    "\n",
    "snippet = pd.json_normalize(info_vac_v1['snippet'])\n",
    "\n",
    "schedule = pd.json_normalize(info_vac_v1['schedule'])\n",
    "schedule.drop(columns=['id'], inplace=True)\n",
    "schedule.rename(columns={'name': 'schedules'}, inplace=True)\n",
    "\n",
    "def sep_list_columns(list):\n",
    "    length = len(list)\n",
    "    if length >= 1:\n",
    "        return list[0]\n",
    "\n",
    "work_format = pd.json_normalize(info_vac_v1['work_format'].apply(sep_list_columns))\n",
    "work_format.rename(columns={'name': 'format_works'}, inplace=True)\n",
    "\n",
    "working_hours = pd.json_normalize(info_vac_v1['working_hours'].apply(sep_list_columns))\n",
    "working_hours.rename(columns={'name': 'hours_working'}, inplace=True)\n",
    "\n",
    "work_schedule_by_days = pd.json_normalize(info_vac_v1['work_schedule_by_days'].apply(sep_list_columns))\n",
    "work_schedule_by_days.rename(columns={'name': 'schedule_work_by_days'}, inplace=True)\n",
    "\n",
    "professional_roles = pd.json_normalize(info_vac_v1['professional_roles'].apply(sep_list_columns))\n",
    "professional_roles.rename(columns={'name': 'roles_professional'}, inplace=True)\n",
    "\n",
    "experience = pd.json_normalize(info_vac_v1['experience'])\n",
    "experience = experience.drop(columns=['id'])\n",
    "experience = experience.rename(columns={'name': 'experience_'})\n",
    "\n",
    "employment = pd.json_normalize(info_vac_v1['employment'])\n",
    "employment = employment.drop(columns=['id'])\n",
    "employment = employment.rename(columns={'name': 'employment_'})\n",
    "\n",
    "info_vac_v1 = pd.concat([info_vac_v1, salary, address, employer, snippet, schedule, work_format['format_works'], working_hours['hours_working'], work_schedule_by_days['schedule_work_by_days'], professional_roles['roles_professional'], experience['experience_'], employment['employment_']], axis = 1)\n",
    "\n",
    "columns_to_drop = [\n",
    "    'area', 'salary', 'employment_form', 'salary_range', 'type', 'address', \n",
    "    'employer', 'contacts', 'snippet', 'schedule', 'work_format', \n",
    "    'employment_form', 'working_hours', 'work_schedule_by_days',\n",
    "    'professional_roles', 'experience', 'employment', 'metro_stations', \n",
    "    'branding', 'department', 'description', 'insider_interview', \n",
    "    'response_url', 'sort_point_distance', 'adv_response_url', 'adv_context',\n",
    "    'metro', 'relations', 'working_days', 'working_time_intervals', \n",
    "    'working_time_modes', 'fly_in_fly_out_duration', 'night_shifts', \n",
    "    'is_adv_vacancy', 'archived', 'show_logo_in_search', 'show_contacts', \n",
    "    'brand_snippet', 'created_at', 'url', 'accept_temporary', \n",
    "    'accept_incomplete_resumes', 'internship', 'metro.station_id', \n",
    "    'metro.line_id', 'metro.lat', 'metro.lng'\n",
    "]\n",
    "\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in info_vac_v1.columns]\n",
    "\n",
    "info_vac_v1 = info_vac_v1.drop(columns=existing_columns_to_drop)\n",
    "\n",
    "exchange_rates = {\n",
    "    'USD': 80.0,  # 1 USD = 80 RUB\n",
    "    'EUR': 90.0,  # 1 EUR = 90 RUB\n",
    "    'RUR': 1.0     # 1 RUB = 1 RUB\n",
    "}\n",
    "\n",
    "def check_salary(row):\n",
    "\n",
    "    if pd.isna(row['to']) and pd.isna(row['from']):\n",
    "        return np.nan\n",
    "    elif pd.isna(row['to']):\n",
    "        total_salary = row['from']\n",
    "    elif pd.isna(row['from']):\n",
    "        total_salary = row['to']\n",
    "    else:\n",
    "        total_salary = (row['from'] + row['to']) / 2\n",
    "\n",
    "    currency = row['currency']\n",
    "    if pd.notna(currency):\n",
    "        total_salary *= exchange_rates.get(currency, 1.0) # Конвертация в рубли\n",
    "    if pd.notna(row['gross']) and row['gross'] == True:\n",
    "        total_salary *= 0.87 # Вычет налогов\n",
    "    return total_salary\n",
    "\n",
    "info_vac_v1['total_salary'] = info_vac_v1.apply(check_salary, axis = 1)"
   ],
   "id": "e0188c6aadca731",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T09:59:13.496605Z",
     "start_time": "2025-07-30T09:56:21.534690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "description_info = []\n",
    "for id in info_vac_v1['id']:\n",
    "    try:\n",
    "        # Делаем запрос к API\n",
    "        req_vac = requests.get(f'https://api.hh.ru/vacancies/{id}') \n",
    "        req_vac.raise_for_status() \n",
    "        data = req_vac.content.decode() \n",
    "        req_vac.close()\n",
    "        \n",
    "        time.sleep(0.4)  # Задержка между запросами\n",
    "        \n",
    "        data_vac = json.loads(data)\n",
    "        \n",
    "        # Обработка skills с проверкой наличия ключа\n",
    "        skills = []\n",
    "        if 'key_skills' in data_vac and isinstance(data_vac['key_skills'], list):\n",
    "            skills = [i['name'] for i in data_vac['key_skills']]\n",
    "        \n",
    "        description_info.append({\n",
    "            'vacancy_id': id,\n",
    "            'description': data_vac.get('description', ''), \n",
    "            'key_skills_under_desc': skills,\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Неожиданная ошибка для вакансии {id}: {e}\")\n",
    "        continue\n",
    "        "
   ],
   "id": "a4cbf1fff30f5f60",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:00:18.444967Z",
     "start_time": "2025-07-30T10:00:18.408685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_description_info = pd.DataFrame(description_info)\n",
    "info_vac_merge = info_vac_v1.merge(df_description_info, left_on='id', right_on='vacancy_id', how='left').drop(columns = ['vacancy_id'])\n",
    "\n",
    "info_vac_merge.rename(columns={'description_y': 'description',\n",
    "                         'key_skills_under_desc_y': 'key_skills_under_desc'}, inplace=True)\n",
    "info_vac_merge.to_csv('info_vac.csv')"
   ],
   "id": "27ccf592dd3d705",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:00:24.566139Z",
     "start_time": "2025-07-30T10:00:19.023268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "skills_keywords = [\n",
    "    # Языки программирования\n",
    "    'SQL', 'Python', 'R', 'Scala', 'Java', 'C#', 'Julia', '1C',\n",
    "    \n",
    "    # BI и визуализация\n",
    "    'Power BI', 'Tableau', 'Qlik', 'Looker', 'Metabase', 'Redash', 'Superset',\n",
    "    'Excel', 'Google Sheets', 'Data Studio', 'Plotly', 'Matplotlib', 'Seaborn',\n",
    "    \n",
    "    # Базы данных\n",
    "    'PostgreSQL', 'MySQL', 'MS SQL', 'Oracle', 'ClickHouse', 'Greenplum',\n",
    "    'MongoDB', 'Redis', 'Cassandra', 'Snowflake', 'BigQuery', 'Redshift',\n",
    "    \n",
    "    # Big Data\n",
    "    'Hadoop', 'Spark', 'Hive', 'Kafka', 'Airflow', 'Flink', 'Databricks',\n",
    "    \n",
    "    # Облачные платформы\n",
    "    'AWS', 'Azure', 'GCP', 'Yandex Cloud', 'IBM Cloud',\n",
    "    \n",
    "    # ETL и обработка данных\n",
    "    'DWH', 'ETL', 'ELT', 'Data Vault', 'Data Lake', 'Data Mesh',\n",
    "    'Informatica', 'Talend', 'SSIS', 'Alteryx', 'dbt', 'Apache NiFi',\n",
    "    \n",
    "    # Аналитика\n",
    "    'Machine Learning', 'ML', 'AI', 'Deep Learning', 'NLP', 'Computer Vision',\n",
    "    'Statistics', 'A/B тестирование', 'Predictive Modeling', 'Time Series',\n",
    "    'EDA', 'Feature Engineering', 'MLflow', 'Kubeflow',\n",
    "    \n",
    "    # Управление\n",
    "    'Scrum', 'Agile', 'Kanban', 'Jira', 'Confluence', 'Git', 'CI/CD',\n",
    "    \n",
    "    # Дополнительные технологии\n",
    "    'Docker', 'Kubernetes', 'Linux', 'Bash', 'Pandas', 'NumPy', 'SciPy',\n",
    "    'Scikit-learn', 'TensorFlow', 'PyTorch', 'Keras', 'XGBoost', 'CatBoost',\n",
    "    'LightGBM', 'OpenCV', 'NLTK', 'spaCy', 'Hugging Face', 'REST', 'API', 'request', 'WebSocket'\n",
    "    \n",
    "    # Математика\n",
    "    'Математика', 'Статистика', 'Математический анализ', 'Линейная алгебра', \n",
    "    'Теория Вероятностей', 'Дискретная математика']\n",
    "\n",
    "\n",
    "def extract_skills(desc):\n",
    "    found_skills = []\n",
    "    desc = str(desc).lower()\n",
    "    for skill in skills_keywords:\n",
    "        if re.search(r'\\b' + re.escape(skill.lower()) + r'\\b', desc):\n",
    "            found_skills.append(skill)\n",
    "    return found_skills\n",
    "\n",
    "nlp = spacy.load(\"ru_core_news_sm\")\n",
    "def check_intern_nlp(desc):\n",
    "    \n",
    "    doc = nlp(desc.lower()) \n",
    "\n",
    "    internship_lemmas = {\n",
    "        \"интерн\", \"стажёр\", \n",
    "        \"intern\", \"trainee\" \n",
    "    }\n",
    "    for token in doc:\n",
    "        # Проверяем лемму (начальную форму) слова\n",
    "        if token.lemma_ in internship_lemmas:\n",
    "            return True\n",
    "            \n",
    "    return False\n",
    "\n",
    "info_vac_merge = pd.read_csv('info_vac.csv', index_col=0)\n",
    "\n",
    "info_vac_merge.columns = map(lambda x: x.replace('.', '_'), info_vac_merge.columns.to_list())\n",
    "\n",
    "info_vac_merge['skills_in_desc'] = info_vac_merge['description'].apply(extract_skills)\n",
    "info_vac_merge = info_vac_merge[info_vac_merge['id'].notna()]\n",
    "info_vac_merge['is_intern'] = info_vac_merge['name'].apply(check_intern_nlp)\n",
    "info_vac_merge = info_vac_merge[info_vac_merge['id_employer'].notna()]\n",
    "info_vac_merge['published_at'] = pd.to_datetime(info_vac_merge['published_at'], utc = True)\n",
    "info_vac_merge.rename(columns={'from': 'from_salary',\n",
    "                               'to': 'to_salary'}, inplace=True)\n",
    "\n",
    "skills_desc = info_vac_merge['skills_in_desc'].explode('skills_in_desc')\n",
    "skills_counts = skills_desc.value_counts()\n",
    "vacancy_skills = info_vac_merge[['id', 'skills_in_desc']].explode('skills_in_desc')\n",
    "\n",
    "employer = info_vac_merge[['id_employer', 'name_employer', 'accredited_it_employer', 'trusted']].drop_duplicates(subset = ['id_employer'], keep = 'first')\n",
    "employer = employer[employer['id_employer'].notna()]\n",
    "\n",
    "info_vac_merge.drop(columns=['name_employer', 'accredited_it_employer', 'trusted'], inplace=True)"
   ],
   "id": "eb22571b31dfef6b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "19fa43e6eb6eaf57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T10:00:27.196907Z",
     "start_time": "2025-07-30T10:00:26.512822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'port': '5433',\n",
    "    'database': 'postgres',\n",
    "    'user': 'postgres',\n",
    "    'password': '123'\n",
    "}\n",
    "\n",
    "with psycopg2.connect(**DB_CONFIG) as conn:\n",
    "    with conn.cursor() as cursor:\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS employers (\n",
    "              id_employer INTEGER PRIMARY KEY,\n",
    "              name_employer VARCHAR(200),\n",
    "              accredited_it_employer TEXT,\n",
    "              trusted BOOLEAN);\n",
    "          \"\"\")\n",
    "        \n",
    "        columns = ', '.join(employer.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(employer.columns))\n",
    "        for _, row in employer.iterrows():\n",
    "            cursor.execute(f\"INSERT INTO employers ({columns}) \"\n",
    "                            f\"VALUES ({placeholders})\"\n",
    "                            f\"ON CONFLICT (id_employer) DO NOTHING\", tuple(row))\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS vacancy (\n",
    "              id INTEGER PRIMARY KEY,\n",
    "              premium BOOLEAN,\n",
    "              name TEXT,\n",
    "              has_test BOOLEAN,\n",
    "              response_letter_required BOOLEAN,\n",
    "              published_at TIMESTAMP WITH TIME ZONE,\n",
    "              apply_alternate_url TEXT,\n",
    "              alternate_url TEXT,\n",
    "              from_salary NUMERIC(10,2),\n",
    "              to_salary NUMERIC(10,2),\n",
    "              currency VARCHAR(20),\n",
    "              gross TEXT,\n",
    "              city TEXT,\n",
    "              street TEXT,\n",
    "              building TEXT,\n",
    "              lat NUMERIC(10,6),\n",
    "              lng NUMERIC(10,6),\n",
    "              raw TEXT,\n",
    "              metro_station_name TEXT,\n",
    "              metro_line_name TEXT,\n",
    "              id_employer INTEGER REFERENCES employers(id_employer),\n",
    "              requirement TEXT,\n",
    "              responsibility TEXT,\n",
    "              schedules TEXT,\n",
    "              format_works TEXT, \n",
    "              hours_working TEXT,\n",
    "              schedule_work_by_days TEXT,\n",
    "              roles_professional TEXT,\n",
    "              experience_ TEXT,\n",
    "              employment_ TEXT, \n",
    "              total_salary NUMERIC(10,2),\n",
    "              description TEXT, \n",
    "              key_skills_under_desc TEXT,\n",
    "              skills_in_desc TEXT,\n",
    "              is_intern BOOLEAN   \n",
    "              );\n",
    "          \"\"\")\n",
    "        \n",
    "        columns = ', '.join(info_vac_merge.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(info_vac_merge.columns))\n",
    "        for _, row in info_vac_merge.iterrows():\n",
    "            cursor.execute(f\"INSERT INTO vacancy ({columns})\"\n",
    "                            f\"VALUES ({placeholders})\"\n",
    "                            f\"ON CONFLICT (id) DO NOTHING\", tuple(row))\n",
    "        conn.commit()\n",
    "        \n",
    "        cursor.execute(\"\"\"\n",
    "          CREATE TABLE IF NOT EXISTS skills (\n",
    "              id INTEGER REFERENCES vacancy(id),\n",
    "              skills_in_desc TEXT\n",
    "              );\n",
    "          \"\"\")\n",
    "        \n",
    "        columns = ', '.join(vacancy_skills.columns)\n",
    "        placeholders = ', '.join(['%s'] * len(vacancy_skills.columns))\n",
    "        for _, row in vacancy_skills.iterrows():\n",
    "            cursor.execute(f\"INSERT INTO skills ({columns})\"\n",
    "                            f\"VALUES ({placeholders})\", tuple(row))\n",
    "        conn.commit()\n",
    "        \n",
    "        "
   ],
   "id": "40a404007711f7ca",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T09:53:22.105624600Z",
     "start_time": "2025-07-15T11:46:24.077999Z"
    }
   },
   "cell_type": "code",
   "source": "vacancy_skills",
   "id": "53f500cc89447a00",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             id skills_in_desc\n",
       "0     122784344            SQL\n",
       "0     122784344             1C\n",
       "0     122784344            Git\n",
       "0     122784344         Docker\n",
       "0     122784344           REST\n",
       "...         ...            ...\n",
       "1904  122146284            SQL\n",
       "1904  122146284       Power BI\n",
       "1904  122146284        Tableau\n",
       "1904  122146284          Excel\n",
       "1905  122774428            NaN\n",
       "\n",
       "[6993 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>skills_in_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122784344</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122784344</td>\n",
       "      <td>1C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122784344</td>\n",
       "      <td>Git</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122784344</td>\n",
       "      <td>Docker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122784344</td>\n",
       "      <td>REST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>122146284</td>\n",
       "      <td>SQL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>122146284</td>\n",
       "      <td>Power BI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>122146284</td>\n",
       "      <td>Tableau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>122146284</td>\n",
       "      <td>Excel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>122774428</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6993 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 103
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d662ae14a07e8c5e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
